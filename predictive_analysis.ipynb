{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Part 2: Predictive Analysis - Review Score Prediction\n",
    "## Predicting Customer Satisfaction Based on Order Features\n",
    "\n",
    "This notebook builds a supervised machine learning model to predict whether a customer review will be high (4-5 stars) or low (1-3 stars) based on order characteristics.\n",
    "\n",
    "**Business Objective**: Enable proactive customer satisfaction management by identifying orders likely to receive poor reviews before the review is submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "orders = pd.read_csv('Data/olist_orders_dataset.csv')\n",
    "order_items = pd.read_csv('Data/olist_order_items_dataset.csv')\n",
    "customers = pd.read_csv('Data/olist_customers_dataset.csv')\n",
    "products = pd.read_csv('Data/olist_products_dataset.csv')\n",
    "payments = pd.read_csv('Data/olist_order_payments_dataset.csv')\n",
    "reviews = pd.read_csv('Data/olist_order_reviews_dataset.csv')\n",
    "sellers = pd.read_csv('Data/olist_sellers_dataset.csv')\n",
    "category_translation = pd.read_csv('Data/product_category_name_translation.csv')\n",
    "\n",
    "print(f\"Reviews dataset shape: {reviews.shape}\")\n",
    "print(f\"\\nReview score distribution:\")\n",
    "print(reviews['review_score'].value_counts().sort_index())\n",
    "\n",
    "# Calculate review score statistics\n",
    "print(f\"\\nReview score statistics:\")\n",
    "print(f\"Mean: {reviews['review_score'].mean():.2f}\")\n",
    "print(f\"Median: {reviews['review_score'].median():.1f}\")\n",
    "print(f\"Mode: {reviews['review_score'].mode().iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Feature Engineering and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable: high review (4-5) vs low review (1-3)\n",
    "reviews['is_high_review'] = (reviews['review_score'] >= 4).astype(int)\n",
    "\n",
    "print(\"Target variable distribution:\")\n",
    "target_dist = reviews['is_high_review'].value_counts()\n",
    "print(f\"Low reviews (1-3): {target_dist[0]} ({target_dist[0]/len(reviews)*100:.1f}%)\")\n",
    "print(f\"High reviews (4-5): {target_dist[1]} ({target_dist[1]/len(reviews)*100:.1f}%)\")\n",
    "\n",
    "# Check for class imbalance\n",
    "class_ratio = target_dist[1] / target_dist[0]\n",
    "print(f\"\\nClass ratio (High:Low): {class_ratio:.2f}:1\")\n",
    "if class_ratio > 2 or class_ratio < 0.5:\n",
    "    print(\"⚠️  Significant class imbalance detected - will need to address in modeling\")\n",
    "else:\n",
    "    print(\"✅ Relatively balanced classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets to create feature set\n",
    "# Start with reviews and orders\n",
    "ml_data = reviews[['order_id', 'review_score', 'is_high_review']].merge(\n",
    "    orders, on='order_id', how='inner'\n",
    ")\n",
    "\n",
    "# Add order items information\n",
    "order_items_agg = order_items.groupby('order_id').agg({\n",
    "    'order_item_id': 'count',  # number of items\n",
    "    'product_id': 'nunique',   # number of unique products\n",
    "    'price': ['sum', 'mean', 'std'],\n",
    "    'freight_value': ['sum', 'mean']\n",
    "}).round(2)\n",
    "\n",
    "order_items_agg.columns = [\n",
    "    'total_items', 'unique_products', 'total_price', 'avg_item_price', 'price_std',\n",
    "    'total_freight', 'avg_freight'\n",
    "]\n",
    "order_items_agg['price_std'] = order_items_agg['price_std'].fillna(0)  # Single item orders\n",
    "\n",
    "ml_data = ml_data.merge(order_items_agg, on='order_id', how='left')\n",
    "\n",
    "# Add payment information\n",
    "payments_agg = payments.groupby('order_id').agg({\n",
    "    'payment_sequential': 'count',  # number of payment methods\n",
    "    'payment_type': lambda x: x.mode().iloc[0] if len(x) > 0 else 'unknown',  # most common payment type\n",
    "    'payment_installments': 'mean',\n",
    "    'payment_value': 'sum'\n",
    "}).round(2)\n",
    "\n",
    "payments_agg.columns = ['payment_methods_count', 'primary_payment_type', 'avg_installments', 'total_payment']\n",
    "\n",
    "ml_data = ml_data.merge(payments_agg, on='order_id', how='left')\n",
    "\n",
    "# Add customer information\n",
    "ml_data = ml_data.merge(customers, on='customer_id', how='left')\n",
    "\n",
    "print(f\"ML dataset shape after merging: {ml_data.shape}\")\n",
    "print(f\"Missing values summary:\")\n",
    "print(ml_data.isnull().sum().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering - Create meaningful features from the data\n",
    "\n",
    "# Convert datetime columns\n",
    "datetime_cols = ['order_purchase_timestamp', 'order_approved_at', \n",
    "                'order_delivered_carrier_date', 'order_delivered_customer_date', \n",
    "                'order_estimated_delivery_date']\n",
    "\n",
    "for col in datetime_cols:\n",
    "    ml_data[col] = pd.to_datetime(ml_data[col])\n",
    "\n",
    "# Delivery performance features\n",
    "ml_data['delivery_days'] = (ml_data['order_delivered_customer_date'] - \n",
    "                           ml_data['order_purchase_timestamp']).dt.days\n",
    "ml_data['estimated_delivery_days'] = (ml_data['order_estimated_delivery_date'] - \n",
    "                                     ml_data['order_purchase_timestamp']).dt.days\n",
    "ml_data['delivery_delay_days'] = (ml_data['order_delivered_customer_date'] - \n",
    "                                 ml_data['order_estimated_delivery_date']).dt.days\n",
    "ml_data['is_delivered_late'] = ml_data['delivery_delay_days'] > 0\n",
    "ml_data['approval_delay_hours'] = (ml_data['order_approved_at'] - \n",
    "                                  ml_data['order_purchase_timestamp']).dt.total_seconds() / 3600\n",
    "\n",
    "# Order timing features\n",
    "ml_data['order_hour'] = ml_data['order_purchase_timestamp'].dt.hour\n",
    "ml_data['order_dayofweek'] = ml_data['order_purchase_timestamp'].dt.dayofweek\n",
    "ml_data['order_month'] = ml_data['order_purchase_timestamp'].dt.month\n",
    "ml_data['is_weekend'] = ml_data['order_dayofweek'].isin([5, 6])\n",
    "\n",
    "# Price and value features\n",
    "ml_data['freight_to_price_ratio'] = ml_data['total_freight'] / (ml_data['total_price'] + 0.01)  # Avoid division by zero\n",
    "ml_data['avg_item_value'] = ml_data['total_price'] / ml_data['total_items']\n",
    "ml_data['is_high_value_order'] = ml_data['total_price'] > ml_data['total_price'].quantile(0.75)\n",
    "\n",
    "# Order complexity features\n",
    "ml_data['product_diversity_ratio'] = ml_data['unique_products'] / ml_data['total_items']\n",
    "ml_data['is_single_item_order'] = ml_data['total_items'] == 1\n",
    "ml_data['has_multiple_payments'] = ml_data['payment_methods_count'] > 1\n",
    "\n",
    "print(\"Feature engineering completed!\")\n",
    "print(f\"Dataset shape: {ml_data.shape}\")\n",
    "\n",
    "# Display some key statistics\n",
    "print(f\"\\nKey feature statistics:\")\n",
    "print(f\"Average delivery days: {ml_data['delivery_days'].mean():.1f}\")\n",
    "print(f\"Late delivery rate: {ml_data['is_delivered_late'].mean()*100:.1f}%\")\n",
    "print(f\"High value orders: {ml_data['is_high_value_order'].mean()*100:.1f}%\")\n",
    "print(f\"Single item orders: {ml_data['is_single_item_order'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "# Only include orders that were delivered (to have complete delivery information)\n",
    "delivered_data = ml_data[ml_data['order_status'] == 'delivered'].copy()\n",
    "\n",
    "print(f\"Filtering to delivered orders: {len(delivered_data)} records ({len(delivered_data)/len(ml_data)*100:.1f}% of total)\")\n",
    "\n",
    "# Define feature sets\n",
    "numerical_features = [\n",
    "    'total_items', 'unique_products', 'total_price', 'avg_item_price', 'price_std',\n",
    "    'total_freight', 'avg_freight', 'avg_installments', 'total_payment',\n",
    "    'delivery_days', 'estimated_delivery_days', 'delivery_delay_days',\n",
    "    'approval_delay_hours', 'order_hour', 'order_dayofweek', 'order_month',\n",
    "    'freight_to_price_ratio', 'avg_item_value', 'product_diversity_ratio'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'order_status', 'primary_payment_type', 'customer_state'\n",
    "]\n",
    "\n",
    "boolean_features = [\n",
    "    'is_delivered_late', 'is_weekend', 'is_high_value_order', \n",
    "    'is_single_item_order', 'has_multiple_payments'\n",
    "]\n",
    "\n",
    "# Combine all features\n",
    "all_features = numerical_features + categorical_features + boolean_features\n",
    "\n",
    "# Check for missing values in selected features\n",
    "feature_missing = delivered_data[all_features].isnull().sum()\n",
    "print(f\"\\nMissing values in selected features:\")\n",
    "print(feature_missing[feature_missing > 0])\n",
    "\n",
    "# Remove rows with missing target or key features\n",
    "delivered_data = delivered_data.dropna(subset=['is_high_review'] + numerical_features[:10])  # Keep most important features\n",
    "\n",
    "print(f\"Final dataset shape: {delivered_data.shape}\")\n",
    "print(f\"Target distribution in final dataset:\")\n",
    "final_target_dist = delivered_data['is_high_review'].value_counts()\n",
    "print(f\"Low reviews: {final_target_dist[0]} ({final_target_dist[0]/len(delivered_data)*100:.1f}%)\")\n",
    "print(f\"High reviews: {final_target_dist[1]} ({final_target_dist[1]/len(delivered_data)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis for Model Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationship between key features and target\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Feature Analysis: High vs Low Reviews', fontsize=16)\n",
    "\n",
    "# 1. Delivery delay impact\n",
    "delivered_data.boxplot(column='delivery_delay_days', by='is_high_review', ax=axes[0,0])\n",
    "axes[0,0].set_title('Delivery Delay vs Review Score')\n",
    "axes[0,0].set_xlabel('Review Score (0=Low, 1=High)')\n",
    "\n",
    "# 2. Order value impact\n",
    "delivered_data.boxplot(column='total_price', by='is_high_review', ax=axes[0,1])\n",
    "axes[0,1].set_title('Order Value vs Review Score')\n",
    "axes[0,1].set_xlabel('Review Score (0=Low, 1=High)')\n",
    "\n",
    "# 3. Freight ratio impact\n",
    "delivered_data.boxplot(column='freight_to_price_ratio', by='is_high_review', ax=axes[0,2])\n",
    "axes[0,2].set_title('Freight/Price Ratio vs Review Score')\n",
    "axes[0,2].set_xlabel('Review Score (0=Low, 1=High)')\n",
    "\n",
    "# 4. Delivery days impact\n",
    "delivered_data.boxplot(column='delivery_days', by='is_high_review', ax=axes[1,0])\n",
    "axes[1,0].set_title('Delivery Days vs Review Score')\n",
    "axes[1,0].set_xlabel('Review Score (0=Low, 1=High)')\n",
    "\n",
    "# 5. Number of items impact\n",
    "delivered_data.boxplot(column='total_items', by='is_high_review', ax=axes[1,1])\n",
    "axes[1,1].set_title('Number of Items vs Review Score')\n",
    "axes[1,1].set_xlabel('Review Score (0=Low, 1=High)')\n",
    "\n",
    "# 6. Installments impact\n",
    "delivered_data.boxplot(column='avg_installments', by='is_high_review', ax=axes[1,2])\n",
    "axes[1,2].set_title('Average Installments vs Review Score')\n",
    "axes[1,2].set_xlabel('Review Score (0=Low, 1=High)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical analysis of key differences\n",
    "print(\"\\nMean differences between high and low review orders:\")\n",
    "comparison_features = ['delivery_delay_days', 'total_price', 'freight_to_price_ratio', \n",
    "                      'delivery_days', 'total_items', 'avg_installments']\n",
    "\n",
    "for feature in comparison_features:\n",
    "    low_mean = delivered_data[delivered_data['is_high_review']==0][feature].mean()\n",
    "    high_mean = delivered_data[delivered_data['is_high_review']==1][feature].mean()\n",
    "    diff_pct = ((high_mean - low_mean) / low_mean * 100) if low_mean != 0 else 0\n",
    "    print(f\"{feature}: Low={low_mean:.2f}, High={high_mean:.2f}, Diff={diff_pct:+.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Payment type vs review score\n",
    "payment_review = pd.crosstab(delivered_data['primary_payment_type'], \n",
    "                           delivered_data['is_high_review'], normalize='index')\n",
    "payment_review.plot(kind='bar', ax=axes[0], title='Payment Type vs Review Score')\n",
    "axes[0].set_xlabel('Payment Type')\n",
    "axes[0].set_ylabel('Proportion')\n",
    "axes[0].legend(['Low Review', 'High Review'])\n",
    "\n",
    "# Late delivery vs review score\n",
    "late_review = pd.crosstab(delivered_data['is_delivered_late'], \n",
    "                         delivered_data['is_high_review'], normalize='index')\n",
    "late_review.plot(kind='bar', ax=axes[1], title='Late Delivery vs Review Score')\n",
    "axes[1].set_xlabel('Delivered Late')\n",
    "axes[1].set_ylabel('Proportion')\n",
    "axes[1].legend(['Low Review', 'High Review'])\n",
    "\n",
    "# Weekend orders vs review score\n",
    "weekend_review = pd.crosstab(delivered_data['is_weekend'], \n",
    "                           delivered_data['is_high_review'], normalize='index')\n",
    "weekend_review.plot(kind='bar', ax=axes[2], title='Weekend Order vs Review Score')\n",
    "axes[2].set_xlabel('Weekend Order')\n",
    "axes[2].set_ylabel('Proportion')\n",
    "axes[2].legend(['Low Review', 'High Review'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print key insights\n",
    "late_delivery_impact = delivered_data.groupby('is_delivered_late')['is_high_review'].mean()\n",
    "print(f\"\\nKey Insights:\")\n",
    "print(f\"On-time delivery high review rate: {late_delivery_impact[False]*100:.1f}%\")\n",
    "print(f\"Late delivery high review rate: {late_delivery_impact[True]*100:.1f}%\")\n",
    "print(f\"Late delivery impact: {(late_delivery_impact[False] - late_delivery_impact[True])*100:.1f} percentage point difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "# Select final feature set (removing features with too many missing values)\n",
    "final_features = [\n",
    "    # Numerical features\n",
    "    'total_items', 'unique_products', 'total_price', 'avg_item_price',\n",
    "    'total_freight', 'avg_freight', 'avg_installments',\n",
    "    'delivery_days', 'delivery_delay_days', 'order_hour', 'order_month',\n",
    "    'freight_to_price_ratio', 'avg_item_value', 'product_diversity_ratio',\n",
    "    # Boolean features (will be treated as numerical)\n",
    "    'is_delivered_late', 'is_weekend', 'is_high_value_order', \n",
    "    'is_single_item_order', 'has_multiple_payments'\n",
    "]\n",
    "\n",
    "# Add important categorical features (encoded)\n",
    "categorical_for_model = ['primary_payment_type', 'customer_state']\n",
    "\n",
    "# Prepare feature matrix\n",
    "X_numerical = delivered_data[final_features].fillna(0)\n",
    "\n",
    "# Encode categorical features\n",
    "X_categorical = pd.get_dummies(delivered_data[categorical_for_model], prefix=categorical_for_model)\n",
    "\n",
    "# Combine features\n",
    "X = pd.concat([X_numerical, X_categorical], axis=1)\n",
    "y = delivered_data['is_high_review']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "print(f\"Feature names: {X.columns.tolist()[:10]}...\")  # Show first 10 features\n",
    "\n",
    "# Check for any remaining missing values\n",
    "missing_check = X.isnull().sum().sum()\n",
    "print(f\"Missing values in feature matrix: {missing_check}\")\n",
    "\n",
    "if missing_check > 0:\n",
    "    X = X.fillna(0)  # Fill any remaining missing values with 0\n",
    "    print(\"Filled remaining missing values with 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Check class distribution in splits\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "train_dist = y_train.value_counts()\n",
    "print(f\"Low: {train_dist[0]} ({train_dist[0]/len(y_train)*100:.1f}%)\")\n",
    "print(f\"High: {train_dist[1]} ({train_dist[1]/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "test_dist = y_test.value_counts()\n",
    "print(f\"Low: {test_dist[0]} ({test_dist[0]/len(y_test)*100:.1f}%)\")\n",
    "print(f\"High: {test_dist[1]} ({test_dist[1]/len(y_test)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models and compare performance\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
    "}\n",
    "\n",
    "# Scale features for Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "print(\"Training models...\\n\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Use scaled data for Logistic Regression, original for tree-based models\n",
    "    if name == 'Logistic Regression':\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc\n",
    "    }\n",
    "    \n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1-Score: {f1:.4f}\")\n",
    "    print(f\"  AUC-ROC: {auc:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Find best model based on F1-score (good balance for slightly imbalanced data)\n",
    "best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['f1'])\n",
    "print(f\"Best performing model: {best_model_name} (F1-Score: {model_results[best_model_name]['f1']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation of the best model\n",
    "best_model = model_results[best_model_name]\n",
    "best_predictions = best_model['predictions']\n",
    "best_probabilities = best_model['probabilities']\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: Confusion Matrix\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Low Review', 'High Review'],\n",
    "            yticklabels=['Low Review', 'High Review'])\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Plot 2: ROC Curve\n",
    "plt.subplot(1, 2, 2)\n",
    "fpr, tpr, _ = roc_curve(y_test, best_probabilities)\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'{best_model_name} (AUC = {best_model[\"auc\"]:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nDetailed Classification Report for {best_model_name}:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, best_predictions, \n",
    "                          target_names=['Low Review (1-3)', 'High Review (4-5)']))\n",
    "\n",
    "# Calculate additional insights\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "npv = tn / (tn + fn)  # Negative Predictive Value\n",
    "\n",
    "print(f\"\\nAdditional Metrics:\")\n",
    "print(f\"Specificity (True Negative Rate): {specificity:.4f}\")\n",
    "print(f\"Negative Predictive Value: {npv:.4f}\")\n",
    "print(f\"False Positive Rate: {fp/(fp+tn):.4f}\")\n",
    "print(f\"False Negative Rate: {fn/(fn+tp):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis (works best with tree-based models)\n",
    "if best_model_name in ['Random Forest', 'Gradient Boosting']:\n",
    "    # Get feature importances\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': best_model['model'].feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Plot top 20 features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance.head(20)\n",
    "    \n",
    "    plt.barh(range(len(top_features)), top_features['importance'], color='skyblue')\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'Top 20 Feature Importances - {best_model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(top_features['importance']):\n",
    "        plt.text(v + 0.001, i, f'{v:.3f}', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nTop 10 Most Important Features for {best_model_name}:\")\n",
    "    print(\"=\" * 60)\n",
    "    for i, (_, row) in enumerate(feature_importance.head(10).iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['feature']:<25} {row['importance']:.4f}\")\n",
    "        \n",
    "else:\n",
    "    # For Logistic Regression, show coefficient magnitudes\n",
    "    feature_coefs = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'coefficient': abs(best_model['model'].coef_[0])\n",
    "    }).sort_values('coefficient', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_coefs.head(20)\n",
    "    \n",
    "    plt.barh(range(len(top_features)), top_features['coefficient'], color='lightcoral')\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Absolute Coefficient Value')\n",
    "    plt.title(f'Top 20 Feature Coefficients (Absolute) - {best_model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nTop 10 Most Important Features for {best_model_name}:\")\n",
    "    print(\"=\" * 60)\n",
    "    for i, (_, row) in enumerate(feature_coefs.head(10).iterrows(), 1):\n",
    "        original_coef = best_model['model'].coef_[0][X.columns.get_loc(row['feature'])]\n",
    "        direction = \"increases\" if original_coef > 0 else \"decreases\"\n",
    "        print(f\"{i:2d}. {row['feature']:<25} {row['coefficient']:.4f} ({direction} probability)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business interpretation of key features\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BUSINESS INTERPRETATION OF KEY FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get top features based on model type\n",
    "if best_model_name in ['Random Forest', 'Gradient Boosting']:\n",
    "    top_features_list = feature_importance.head(5)['feature'].tolist()\n",
    "    importance_values = feature_importance.head(5)['importance'].tolist()\n",
    "else:\n",
    "    top_features_list = feature_coefs.head(5)['feature'].tolist()\n",
    "    importance_values = feature_coefs.head(5)['coefficient'].tolist()\n",
    "\n",
    "feature_interpretations = {\n",
    "    'is_delivered_late': 'Late delivery is the strongest predictor of low reviews',\n",
    "    'delivery_delay_days': 'Number of days late significantly impacts customer satisfaction',\n",
    "    'delivery_days': 'Longer overall delivery time correlates with lower satisfaction',\n",
    "    'freight_to_price_ratio': 'High shipping costs relative to product price hurt satisfaction',\n",
    "    'total_price': 'Order value affects review patterns (high-value customers may be more critical)',\n",
    "    'avg_installments': 'Payment terms influence customer satisfaction',\n",
    "    'total_items': 'Order complexity (number of items) impacts delivery success',\n",
    "    'order_hour': 'Time of day when order was placed affects logistics performance',\n",
    "    'avg_item_value': 'Individual item value influences customer expectations',\n",
    "    'is_weekend': 'Weekend orders may have different processing patterns'\n",
    "}\n",
    "\n",
    "print(f\"\\nTop predictive factors for customer satisfaction:\")\n",
    "for i, (feature, importance) in enumerate(zip(top_features_list, importance_values), 1):\n",
    "    interpretation = feature_interpretations.get(feature, 'Custom feature requiring domain analysis')\n",
    "    print(f\"{i}. {feature} (importance: {importance:.4f})\")\n",
    "    print(f\"   → {interpretation}\")\n",
    "    print()\n",
    "\n",
    "# Calculate business impact metrics\n",
    "late_delivery_impact = delivered_data.groupby('is_delivered_late')['is_high_review'].mean()\n",
    "high_freight_impact = delivered_data.groupby(delivered_data['freight_to_price_ratio'] > 0.2)['is_high_review'].mean()\n",
    "\n",
    "print(f\"Key Business Metrics:\")\n",
    "print(f\"• On-time delivery satisfaction: {late_delivery_impact[False]*100:.1f}%\")\n",
    "print(f\"• Late delivery satisfaction: {late_delivery_impact[True]*100:.1f}%\")\n",
    "print(f\"• Impact of late delivery: {(late_delivery_impact[False] - late_delivery_impact[True])*100:.1f} percentage points\")\n",
    "print(f\"• High freight ratio (>20%) satisfaction: {high_freight_impact[True]*100:.1f}%\")\n",
    "print(f\"• Low freight ratio (≤20%) satisfaction: {high_freight_impact[False]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Model Performance Summary and Business Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation to assess model stability\n",
    "print(\"Performing cross-validation analysis...\\n\")\n",
    "\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    cv_scores = cross_val_score(best_model['model'], X_train_scaled, y_train, cv=5, scoring='f1')\n",
    "else:\n",
    "    cv_scores = cross_val_score(best_model['model'], X_train, y_train, cv=5, scoring='f1')\n",
    "\n",
    "print(f\"Cross-Validation Results ({best_model_name}):\")\n",
    "print(f\"F1-Score: {cv_scores.mean():.4f} ± {cv_scores.std()*2:.4f}\")\n",
    "print(f\"Individual fold scores: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "\n",
    "# Model stability check\n",
    "if cv_scores.std() < 0.02:\n",
    "    print(\"✅ Model shows good stability across folds\")\n",
    "elif cv_scores.std() < 0.05:\n",
    "    print(\"⚠️  Moderate variability across folds\")\n",
    "else:\n",
    "    print(\"❌ High variability - model may be unstable\")\n",
    "\n",
    "# Business value calculation\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"BUSINESS VALUE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate potential impact\n",
    "total_orders = len(y_test)\n",
    "predicted_low_reviews = (best_predictions == 0).sum()\n",
    "actual_low_reviews = (y_test == 0).sum()\n",
    "true_positives = tp  # Correctly identified high reviews\n",
    "false_negatives = fn  # Missed low reviews (high risk)\n",
    "true_negatives = tn  # Correctly identified low reviews\n",
    "false_positives = fp  # Incorrectly flagged as low review\n",
    "\n",
    "print(f\"Model Performance on Test Set ({total_orders:,} orders):\")\n",
    "print(f\"• Correctly identified high reviews: {true_positives:,} orders\")\n",
    "print(f\"• Correctly identified low reviews: {true_negatives:,} orders\")\n",
    "print(f\"• Missed low reviews (high risk): {false_negatives:,} orders\")\n",
    "print(f\"• False alarms: {false_positives:,} orders\")\n",
    "\n",
    "# Business impact estimates\n",
    "intervention_cost_per_order = 10  # Assumed cost to intervene (proactive customer service)\n",
    "churn_cost_per_customer = 150    # Assumed customer lifetime value loss\n",
    "intervention_success_rate = 0.3  # Assumed success rate of intervention\n",
    "\n",
    "# Calculate costs and savings\n",
    "intervention_cost = true_negatives * intervention_cost_per_order\n",
    "false_alarm_cost = false_positives * intervention_cost_per_order\n",
    "missed_opportunity_cost = false_negatives * churn_cost_per_customer * intervention_success_rate\n",
    "prevented_churn_value = true_negatives * churn_cost_per_customer * intervention_success_rate\n",
    "\n",
    "net_value = prevented_churn_value - intervention_cost - false_alarm_cost\n",
    "\n",
    "print(f\"\\nEstimated Business Impact (Test Set):\")\n",
    "print(f\"• Intervention cost: R$ {intervention_cost:,.2f}\")\n",
    "print(f\"• False alarm cost: R$ {false_alarm_cost:,.2f}\")\n",
    "print(f\"• Prevented churn value: R$ {prevented_churn_value:,.2f}\")\n",
    "print(f\"• Missed opportunity cost: R$ {missed_opportunity_cost:,.2f}\")\n",
    "print(f\"• Net business value: R$ {net_value:,.2f}\")\n",
    "\n",
    "roi = (net_value / (intervention_cost + false_alarm_cost)) * 100\n",
    "print(f\"• ROI: {roi:.1f}%\")\n",
    "\n",
    "if net_value > 0:\n",
    "    print(\"✅ Model provides positive business value\")\n",
    "else:\n",
    "    print(\"❌ Model needs improvement or different intervention strategy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Model Limitations and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MODEL LIMITATIONS AND IMPROVEMENT OPPORTUNITIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Class imbalance analysis\n",
    "class_distribution = y.value_counts(normalize=True)\n",
    "print(f\"\\n1. CLASS IMBALANCE ANALYSIS:\")\n",
    "print(f\"   • High reviews: {class_distribution[1]*100:.1f}%\")\n",
    "print(f\"   • Low reviews: {class_distribution[0]*100:.1f}%\")\n",
    "print(f\"   • Imbalance ratio: {class_distribution[1]/class_distribution[0]:.2f}:1\")\n",
    "\n",
    "if class_distribution[1]/class_distribution[0] > 3:\n",
    "    print(\"   ⚠️  Significant class imbalance - model may be biased toward predicting high reviews\")\n",
    "    print(\"   💡 Recommendation: Use SMOTE, cost-sensitive learning, or threshold tuning\")\n",
    "\n",
    "# Feature coverage analysis\n",
    "missing_data_pct = delivered_data[final_features].isnull().sum().sum() / (len(delivered_data) * len(final_features)) * 100\n",
    "print(f\"\\n2. DATA QUALITY:\")\n",
    "print(f\"   • Missing data: {missing_data_pct:.2f}% of feature values\")\n",
    "print(f\"   • Dataset coverage: {len(delivered_data):,} orders ({len(delivered_data)/len(ml_data)*100:.1f}% of total)\")\n",
    "\n",
    "# Temporal bias\n",
    "date_range = delivered_data['order_purchase_timestamp'].dt.date\n",
    "print(f\"\\n3. TEMPORAL LIMITATIONS:\")\n",
    "print(f\"   • Date range: {date_range.min()} to {date_range.max()}\")\n",
    "print(f\"   • Time span: {(date_range.max() - date_range.min()).days} days\")\n",
    "print(f\"   ⚠️  Model trained on historical data - may not capture current market conditions\")\n",
    "print(f\"   💡 Recommendation: Implement model retraining pipeline with recent data\")\n",
    "\n",
    "# Feature engineering opportunities\n",
    "print(f\"\\n4. MISSING FEATURES (Potential Improvements):\")\n",
    "missing_features = [\n",
    "    \"Product category satisfaction history\",\n",
    "    \"Seller performance metrics\",\n",
    "    \"Customer purchase history/loyalty\",\n",
    "    \"Seasonal/holiday effects\",\n",
    "    \"Geographic distance (customer-seller)\",\n",
    "    \"Product reviews/ratings\",\n",
    "    \"Competitor pricing data\",\n",
    "    \"Customer demographics\",\n",
    "    \"Weather/external factors\",\n",
    "    \"Marketing campaign exposure\"\n",
    "]\n",
    "\n",
    "for i, feature in enumerate(missing_features, 1):\n",
    "    print(f\"   {i:2d}. {feature}\")\n",
    "\n",
    "print(f\"\\n5. SCALABILITY CONSIDERATIONS:\")\n",
    "print(f\"   • Current feature count: {X.shape[1]}\")\n",
    "print(f\"   • Training time: Acceptable for current dataset size\")\n",
    "print(f\"   • Memory usage: {X.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "print(f\"   💡 For production: Consider feature selection, model simplification, or ensemble approaches\")\n",
    "\n",
    "print(f\"\\n6. BUSINESS DEPLOYMENT RECOMMENDATIONS:\")\n",
    "recommendations = [\n",
    "    \"Implement real-time scoring for new orders\",\n",
    "    \"Set up A/B testing framework for intervention strategies\",\n",
    "    \"Create monitoring dashboard for model performance drift\",\n",
    "    \"Establish feedback loop to capture intervention outcomes\",\n",
    "    \"Develop tiered intervention strategy based on prediction confidence\",\n",
    "    \"Integration with customer service workflows\",\n",
    "    \"Regular model retraining (monthly/quarterly)\",\n",
    "    \"Expand to predict specific review scores (1-5) instead of binary\"\n",
    "]\n",
    "\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"   {i}. {rec}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"FINAL MODEL SUMMARY\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_model['accuracy']:.3f} | Precision: {best_model['precision']:.3f} | Recall: {best_model['recall']:.3f}\")\n",
    "print(f\"F1-Score: {best_model['f1']:.3f} | AUC-ROC: {best_model['auc']:.3f}\")\n",
    "print(f\"Cross-validation F1: {cv_scores.mean():.3f} ± {cv_scores.std()*2:.3f}\")\n",
    "print(f\"Estimated ROI: {roi:.1f}%\")\n",
    "print(f\"Deployment Ready: {'✅ Yes' if best_model['f1'] > 0.7 and cv_scores.std() < 0.05 else '⚠️  Needs improvement'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
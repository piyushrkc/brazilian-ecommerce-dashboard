{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Brazilian E-Commerce Analysis: Retrospective Insights\n",
    "## Delivery Performance & Customer Retention Analysis\n",
    "\n",
    "This notebook provides a comprehensive analysis of the Olist Brazilian E-Commerce dataset focusing on:\n",
    "1. **Delivery Performance Analysis** - Late vs on-time deliveries by product category\n",
    "2. **Customer Retention Analysis** - RFM segmentation and lifetime value calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "orders = pd.read_csv('Data/olist_orders_dataset.csv')\n",
    "order_items = pd.read_csv('Data/olist_order_items_dataset.csv')\n",
    "customers = pd.read_csv('Data/olist_customers_dataset.csv')\n",
    "products = pd.read_csv('Data/olist_products_dataset.csv')\n",
    "payments = pd.read_csv('Data/olist_order_payments_dataset.csv')\n",
    "reviews = pd.read_csv('Data/olist_order_reviews_dataset.csv')\n",
    "sellers = pd.read_csv('Data/olist_sellers_dataset.csv')\n",
    "geolocation = pd.read_csv('Data/olist_geolocation_dataset.csv')\n",
    "category_translation = pd.read_csv('Data/product_category_name_translation.csv')\n",
    "\n",
    "print(f\"Orders: {orders.shape}\")\n",
    "print(f\"Order Items: {order_items.shape}\")\n",
    "print(f\"Customers: {customers.shape}\")\n",
    "print(f\"Products: {products.shape}\")\n",
    "print(f\"Payments: {payments.shape}\")\n",
    "print(f\"Reviews: {reviews.shape}\")\n",
    "print(f\"Sellers: {sellers.shape}\")\n",
    "print(f\"Geolocation: {geolocation.shape}\")\n",
    "print(f\"Category Translation: {category_translation.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and datetime conversion\n",
    "orders['order_purchase_timestamp'] = pd.to_datetime(orders['order_purchase_timestamp'])\n",
    "orders['order_delivered_customer_date'] = pd.to_datetime(orders['order_delivered_customer_date'])\n",
    "orders['order_estimated_delivery_date'] = pd.to_datetime(orders['order_estimated_delivery_date'])\n",
    "orders['order_approved_at'] = pd.to_datetime(orders['order_approved_at'])\n",
    "orders['order_delivered_carrier_date'] = pd.to_datetime(orders['order_delivered_carrier_date'])\n",
    "\n",
    "# Calculate delivery performance metrics\n",
    "orders['delivery_days'] = (orders['order_delivered_customer_date'] - orders['order_purchase_timestamp']).dt.days\n",
    "orders['estimated_delivery_days'] = (orders['order_estimated_delivery_date'] - orders['order_purchase_timestamp']).dt.days\n",
    "orders['delivery_delay_days'] = (orders['order_delivered_customer_date'] - orders['order_estimated_delivery_date']).dt.days\n",
    "orders['is_late'] = orders['delivery_delay_days'] > 0\n",
    "\n",
    "# Filter only delivered orders for delivery analysis\n",
    "delivered_orders = orders[orders['order_status'] == 'delivered'].copy()\n",
    "\n",
    "print(f\"Total orders: {len(orders)}\")\n",
    "print(f\"Delivered orders: {len(delivered_orders)}\")\n",
    "print(f\"Late deliveries: {delivered_orders['is_late'].sum()} ({delivered_orders['is_late'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Part 1: Delivery Performance Analysis\n",
    "### Advanced Visualization: Waterfall Chart for Delivery Performance by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data for delivery analysis\n",
    "delivery_analysis = delivered_orders.merge(order_items, on='order_id')\n",
    "delivery_analysis = delivery_analysis.merge(products, on='product_id')\n",
    "delivery_analysis = delivery_analysis.merge(category_translation, on='product_category_name', how='left')\n",
    "\n",
    "# Calculate delivery performance by category\n",
    "category_performance = delivery_analysis.groupby('product_category_name_english').agg({\n",
    "    'is_late': ['count', 'sum', 'mean'],\n",
    "    'delivery_delay_days': ['mean', 'median'],\n",
    "    'delivery_days': ['mean', 'median'],\n",
    "    'price': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "category_performance.columns = ['total_orders', 'late_orders', 'late_rate', 'avg_delay_days', 'median_delay_days', 'avg_delivery_days', 'median_delivery_days', 'avg_price']\n",
    "category_performance = category_performance[category_performance['total_orders'] >= 100].sort_values('late_rate', ascending=False)\n",
    "\n",
    "print(\"Top 10 Categories with Highest Late Delivery Rates:\")\n",
    "print(category_performance.head(10)[['total_orders', 'late_rate', 'avg_delay_days']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sophisticated waterfall chart for delivery performance\n",
    "top_categories = category_performance.head(15)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Calculate cumulative effect\n",
    "baseline_late_rate = delivered_orders['is_late'].mean()\n",
    "cumulative_effect = 0\n",
    "\n",
    "x_labels = []\n",
    "y_values = []\n",
    "colors = []\n",
    "text_values = []\n",
    "\n",
    "# Add baseline\n",
    "x_labels.append('Overall Rate')\n",
    "y_values.append(baseline_late_rate * 100)\n",
    "colors.append('blue')\n",
    "text_values.append(f'{baseline_late_rate*100:.1f}%')\n",
    "\n",
    "# Add category impacts\n",
    "for category, row in top_categories.iterrows():\n",
    "    category_impact = (row['late_rate'] - baseline_late_rate) * 100\n",
    "    x_labels.append(category[:20] + '...' if len(category) > 20 else category)\n",
    "    y_values.append(category_impact)\n",
    "    colors.append('red' if category_impact > 0 else 'green')\n",
    "    text_values.append(f'{row[\"late_rate\"]*100:.1f}%')\n",
    "\n",
    "fig.add_trace(go.Waterfall(\n",
    "    name=\"Delivery Performance\",\n",
    "    orientation=\"v\",\n",
    "    measure=[\"absolute\"] + [\"relative\"] * len(top_categories),\n",
    "    x=x_labels,\n",
    "    y=y_values,\n",
    "    text=text_values,\n",
    "    textposition=\"outside\",\n",
    "    connector={\"line\":{\"color\":\"rgb(63, 63, 63)\"}},\n",
    "    increasing={\"marker\":{\"color\":\"red\"}},\n",
    "    decreasing={\"marker\":{\"color\":\"green\"}},\n",
    "    totals={\"marker\":{\"color\":\"blue\"}}\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Delivery Performance Waterfall: Late Delivery Rates by Product Category<br><sub>Categories with >100 orders, showing deviation from overall rate</sub>\",\n",
    "    xaxis_title=\"Product Categories\",\n",
    "    yaxis_title=\"Late Delivery Rate (%)\",\n",
    "    height=600,\n",
    "    showlegend=False,\n",
    "    xaxis_tickangle=-45\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nOverall late delivery rate: {baseline_late_rate*100:.1f}%\")\n",
    "print(f\"Worst performing category: {top_categories.index[0]} ({top_categories.iloc[0]['late_rate']*100:.1f}%)\")\n",
    "print(f\"Best performing category: {top_categories.index[-1]} ({top_categories.iloc[-1]['late_rate']*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sankey diagram for delivery flow analysis\n",
    "# Analyze delivery performance by state and category\n",
    "state_category_analysis = delivery_analysis.merge(customers, on='customer_id')\n",
    "state_performance = state_category_analysis.groupby(['customer_state', 'product_category_name_english']).agg({\n",
    "    'is_late': ['count', 'sum'],\n",
    "    'delivery_days': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "state_performance.columns = ['total_orders', 'late_orders', 'avg_delivery_days']\n",
    "state_performance['late_rate'] = state_performance['late_orders'] / state_performance['total_orders']\n",
    "state_performance = state_performance[state_performance['total_orders'] >= 50].reset_index()\n",
    "\n",
    "# Get top states and categories for Sankey\n",
    "top_states = state_performance.groupby('customer_state')['total_orders'].sum().nlargest(8).index.tolist()\n",
    "top_cats = state_performance.groupby('product_category_name_english')['total_orders'].sum().nlargest(10).index.tolist()\n",
    "\n",
    "sankey_data = state_performance[\n",
    "    (state_performance['customer_state'].isin(top_states)) & \n",
    "    (state_performance['product_category_name_english'].isin(top_cats))\n",
    "]\n",
    "\n",
    "# Create Sankey diagram\n",
    "states = sankey_data['customer_state'].unique().tolist()\n",
    "categories = sankey_data['product_category_name_english'].unique().tolist()\n",
    "performance_levels = ['On Time', 'Late']\n",
    "\n",
    "all_nodes = states + categories + performance_levels\n",
    "node_colors = ['lightblue'] * len(states) + ['lightgreen'] * len(categories) + ['green', 'red']\n",
    "\n",
    "source = []\n",
    "target = []\n",
    "value = []\n",
    "link_colors = []\n",
    "\n",
    "for _, row in sankey_data.iterrows():\n",
    "    state_idx = all_nodes.index(row['customer_state'])\n",
    "    cat_idx = all_nodes.index(row['product_category_name_english'])\n",
    "    \n",
    "    # State to Category\n",
    "    source.append(state_idx)\n",
    "    target.append(cat_idx)\n",
    "    value.append(row['total_orders'])\n",
    "    link_colors.append('rgba(0,0,255,0.3)')\n",
    "    \n",
    "    # Category to Performance\n",
    "    on_time_orders = row['total_orders'] - row['late_orders']\n",
    "    \n",
    "    if on_time_orders > 0:\n",
    "        source.append(cat_idx)\n",
    "        target.append(all_nodes.index('On Time'))\n",
    "        value.append(on_time_orders)\n",
    "        link_colors.append('rgba(0,255,0,0.3)')\n",
    "    \n",
    "    if row['late_orders'] > 0:\n",
    "        source.append(cat_idx)\n",
    "        target.append(all_nodes.index('Late'))\n",
    "        value.append(row['late_orders'])\n",
    "        link_colors.append('rgba(255,0,0,0.3)')\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=all_nodes,\n",
    "        color=node_colors\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=source,\n",
    "        target=target,\n",
    "        value=value,\n",
    "        color=link_colors\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Delivery Performance Flow: States → Categories → Performance<br><sub>Top 8 states and top 10 categories by order volume</sub>\",\n",
    "    font_size=10,\n",
    "    height=700\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Part 2: Customer Retention Analysis - RFM Segmentation\n",
    "### Advanced Visualization: RFM 3D Scatter Plot and Customer Lifetime Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RFM metrics\n",
    "# First, create customer transaction summary\n",
    "customer_orders = orders.merge(order_items, on='order_id')\n",
    "customer_orders = customer_orders.merge(payments.groupby('order_id')['payment_value'].sum().reset_index(), on='order_id')\n",
    "customer_orders = customer_orders.merge(customers, on='customer_id')\n",
    "\n",
    "# Set analysis date as the last date in dataset\n",
    "analysis_date = customer_orders['order_purchase_timestamp'].max()\n",
    "print(f\"Analysis date: {analysis_date}\")\n",
    "\n",
    "# Calculate RFM metrics\n",
    "rfm_data = customer_orders.groupby('customer_unique_id').agg({\n",
    "    'order_purchase_timestamp': ['max', 'count'],\n",
    "    'payment_value': ['sum', 'mean']\n",
    "}).round(2)\n",
    "\n",
    "rfm_data.columns = ['last_purchase_date', 'frequency', 'total_spent', 'avg_order_value']\n",
    "rfm_data['recency'] = (analysis_date - rfm_data['last_purchase_date']).dt.days\n",
    "rfm_data['monetary'] = rfm_data['total_spent']\n",
    "\n",
    "print(f\"RFM Data Shape: {rfm_data.shape}\")\n",
    "print(f\"\\nRFM Summary:\")\n",
    "print(rfm_data[['recency', 'frequency', 'monetary']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RFM scores using quintiles\n",
    "rfm_data['R_score'] = pd.qcut(rfm_data['recency'], 5, labels=[5,4,3,2,1])  # Lower recency = higher score\n",
    "rfm_data['F_score'] = pd.qcut(rfm_data['frequency'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
    "rfm_data['M_score'] = pd.qcut(rfm_data['monetary'], 5, labels=[1,2,3,4,5])\n",
    "\n",
    "# Convert to numeric for calculations\n",
    "rfm_data['R_score'] = rfm_data['R_score'].astype(int)\n",
    "rfm_data['F_score'] = rfm_data['F_score'].astype(int)\n",
    "rfm_data['M_score'] = rfm_data['M_score'].astype(int)\n",
    "\n",
    "# Create RFM segments\n",
    "def segment_customers(row):\n",
    "    if row['R_score'] >= 4 and row['F_score'] >= 4 and row['M_score'] >= 4:\n",
    "        return 'Champions'\n",
    "    elif row['R_score'] >= 3 and row['F_score'] >= 3 and row['M_score'] >= 3:\n",
    "        return 'Loyal Customers'\n",
    "    elif row['R_score'] >= 4 and row['F_score'] <= 2:\n",
    "        return 'New Customers'\n",
    "    elif row['R_score'] >= 3 and row['F_score'] >= 2 and row['M_score'] >= 2:\n",
    "        return 'Potential Loyalists'\n",
    "    elif row['R_score'] >= 3 and row['F_score'] <= 2:\n",
    "        return 'Promising'\n",
    "    elif row['R_score'] <= 2 and row['F_score'] >= 3:\n",
    "        return 'At Risk'\n",
    "    elif row['R_score'] <= 2 and row['F_score'] <= 2 and row['M_score'] >= 3:\n",
    "        return \"Can't Lose Them\"\n",
    "    elif row['R_score'] <= 2 and row['F_score'] <= 2:\n",
    "        return 'Lost Customers'\n",
    "    else:\n",
    "        return 'Others'\n",
    "\n",
    "rfm_data['segment'] = rfm_data.apply(segment_customers, axis=1)\n",
    "\n",
    "# Display segment distribution\n",
    "segment_summary = rfm_data.groupby('segment').agg({\n",
    "    'recency': 'mean',\n",
    "    'frequency': 'mean',\n",
    "    'monetary': 'mean',\n",
    "    'avg_order_value': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "segment_counts = rfm_data['segment'].value_counts()\n",
    "segment_summary['count'] = segment_counts\n",
    "segment_summary['percentage'] = (segment_counts / len(rfm_data) * 100).round(1)\n",
    "\n",
    "print(\"Customer Segment Analysis:\")\n",
    "print(segment_summary.sort_values('monetary', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create advanced 3D RFM visualization\n",
    "fig = px.scatter_3d(\n",
    "    rfm_data.reset_index(), \n",
    "    x='recency', \n",
    "    y='frequency', \n",
    "    z='monetary',\n",
    "    color='segment',\n",
    "    size='avg_order_value',\n",
    "    hover_data=['customer_unique_id'],\n",
    "    title=\"3D RFM Customer Segmentation Analysis<br><sub>Recency (days) vs Frequency (orders) vs Monetary (total spent)</sub>\",\n",
    "    labels={\n",
    "        'recency': 'Recency (Days Since Last Purchase)',\n",
    "        'frequency': 'Frequency (Number of Orders)',\n",
    "        'monetary': 'Monetary (Total Spent R$)'\n",
    "    },\n",
    "    height=700\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(line=dict(width=0.5, color='DarkSlateGrey')))\n",
    "fig.show()\n",
    "\n",
    "# Create segment treemap\n",
    "segment_treemap_data = segment_summary.reset_index()\n",
    "segment_treemap_data['label'] = segment_treemap_data['segment'] + '<br>' + segment_treemap_data['percentage'].astype(str) + '%'\n",
    "\n",
    "fig2 = px.treemap(\n",
    "    segment_treemap_data,\n",
    "    path=['segment'],\n",
    "    values='count',\n",
    "    color='monetary',\n",
    "    color_continuous_scale='RdYlGn',\n",
    "    title=\"Customer Segment Distribution (Size = Count, Color = Average Monetary Value)\",\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Customer Lifetime Value (CLV)\n",
    "# CLV = (Average Order Value) × (Purchase Frequency) × (Customer Lifespan)\n",
    "\n",
    "# Calculate customer lifespan (days between first and last purchase)\n",
    "customer_lifespan = customer_orders.groupby('customer_unique_id')['order_purchase_timestamp'].agg(['min', 'max'])\n",
    "customer_lifespan['lifespan_days'] = (customer_lifespan['max'] - customer_lifespan['min']).dt.days\n",
    "customer_lifespan['lifespan_days'] = customer_lifespan['lifespan_days'].fillna(0)  # Single purchase customers\n",
    "\n",
    "# Merge with RFM data\n",
    "rfm_clv = rfm_data.merge(customer_lifespan[['lifespan_days']], left_index=True, right_index=True)\n",
    "\n",
    "# Calculate purchase frequency per day (to annualize)\n",
    "rfm_clv['purchase_frequency_per_day'] = rfm_clv['frequency'] / (rfm_clv['lifespan_days'] + 1)  # +1 to avoid division by zero\n",
    "\n",
    "# Estimate annual CLV\n",
    "rfm_clv['estimated_annual_clv'] = rfm_clv['avg_order_value'] * rfm_clv['purchase_frequency_per_day'] * 365\n",
    "\n",
    "# For customers with only one purchase, use a different approach\n",
    "single_purchase_mask = rfm_clv['frequency'] == 1\n",
    "rfm_clv.loc[single_purchase_mask, 'estimated_annual_clv'] = rfm_clv.loc[single_purchase_mask, 'avg_order_value'] * 0.5  # Conservative estimate\n",
    "\n",
    "# Calculate CLV by segment\n",
    "clv_by_segment = rfm_clv.groupby('segment').agg({\n",
    "    'estimated_annual_clv': ['mean', 'median', 'sum'],\n",
    "    'frequency': 'mean',\n",
    "    'avg_order_value': 'mean',\n",
    "    'lifespan_days': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "clv_by_segment.columns = ['avg_clv', 'median_clv', 'total_clv', 'avg_frequency', 'avg_order_value', 'avg_lifespan_days']\n",
    "clv_by_segment['customer_count'] = rfm_clv['segment'].value_counts()\n",
    "\n",
    "print(\"Customer Lifetime Value Analysis by Segment:\")\n",
    "print(clv_by_segment.sort_values('avg_clv', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create advanced CLV visualization - Mekko Chart\n",
    "clv_viz_data = clv_by_segment.reset_index()\n",
    "clv_viz_data['clv_per_customer'] = clv_viz_data['total_clv'] / clv_viz_data['customer_count']\n",
    "\n",
    "# Create subplot with multiple visualizations\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=(\n",
    "        'CLV Distribution by Segment',\n",
    "        'Customer Count vs Average CLV',\n",
    "        'Total CLV Contribution by Segment',\n",
    "        'CLV vs Purchase Behavior'\n",
    "    ),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"scatter\"}],\n",
    "           [{\"type\": \"bar\"}, {\"type\": \"scatter\"}]]\n",
    ")\n",
    "\n",
    "# Plot 1: CLV Distribution\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=clv_viz_data['segment'],\n",
    "        y=clv_viz_data['avg_clv'],\n",
    "        name='Avg CLV',\n",
    "        marker_color='lightcoral'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Plot 2: Customer Count vs CLV\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=clv_viz_data['customer_count'],\n",
    "        y=clv_viz_data['avg_clv'],\n",
    "        mode='markers+text',\n",
    "        text=clv_viz_data['segment'],\n",
    "        textposition='top center',\n",
    "        marker=dict(size=clv_viz_data['avg_order_value']/5, color='lightblue'),\n",
    "        name='Segments'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Plot 3: Total CLV Contribution\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=clv_viz_data['segment'],\n",
    "        y=clv_viz_data['total_clv'],\n",
    "        name='Total CLV',\n",
    "        marker_color='lightgreen'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Plot 4: CLV vs Frequency\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=clv_viz_data['avg_frequency'],\n",
    "        y=clv_viz_data['avg_clv'],\n",
    "        mode='markers+text',\n",
    "        text=clv_viz_data['segment'],\n",
    "        textposition='top center',\n",
    "        marker=dict(size=clv_viz_data['customer_count']/100, color='orange'),\n",
    "        name='CLV vs Frequency'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    title_text=\"Customer Lifetime Value Analysis Dashboard\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Customer Segments\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Customer Count\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Customer Segments\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Average Frequency\", row=2, col=2)\n",
    "\n",
    "fig.update_yaxes(title_text=\"Average CLV (R$)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Average CLV (R$)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Total CLV (R$)\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Average CLV (R$)\", row=2, col=2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Summary statistics\n",
    "total_clv = clv_viz_data['total_clv'].sum()\n",
    "top_segment = clv_viz_data.loc[clv_viz_data['avg_clv'].idxmax(), 'segment']\n",
    "top_contributor = clv_viz_data.loc[clv_viz_data['total_clv'].idxmax(), 'segment']\n",
    "\n",
    "print(f\"\\nCLV Summary:\")\n",
    "print(f\"Total estimated CLV: R$ {total_clv:,.2f}\")\n",
    "print(f\"Highest value per customer: {top_segment}\")\n",
    "print(f\"Largest total contribution: {top_contributor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Geographic and Bias Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze geographic distribution and potential biases\n",
    "geo_analysis = customer_orders.merge(customers, on='customer_id')\n",
    "state_summary = geo_analysis.groupby('customer_state').agg({\n",
    "    'customer_id': 'nunique',\n",
    "    'order_id': 'nunique',\n",
    "    'payment_value': ['sum', 'mean'],\n",
    "    'order_purchase_timestamp': ['min', 'max']\n",
    "}).round(2)\n",
    "\n",
    "state_summary.columns = ['unique_customers', 'total_orders', 'total_revenue', 'avg_order_value', 'first_order', 'last_order']\n",
    "state_summary['orders_per_customer'] = (state_summary['total_orders'] / state_summary['unique_customers']).round(2)\n",
    "state_summary = state_summary.sort_values('total_revenue', ascending=False)\n",
    "\n",
    "print(\"Geographic Distribution Analysis:\")\n",
    "print(\"Top 10 States by Revenue:\")\n",
    "print(state_summary.head(10))\n",
    "\n",
    "# Calculate concentration metrics\n",
    "total_revenue = state_summary['total_revenue'].sum()\n",
    "total_customers = state_summary['unique_customers'].sum()\n",
    "total_orders = state_summary['total_orders'].sum()\n",
    "\n",
    "# Top 3 states concentration\n",
    "top3_revenue_share = state_summary.head(3)['total_revenue'].sum() / total_revenue * 100\n",
    "top3_customer_share = state_summary.head(3)['unique_customers'].sum() / total_customers * 100\n",
    "top3_order_share = state_summary.head(3)['total_orders'].sum() / total_orders * 100\n",
    "\n",
    "print(f\"\\nGeographic Concentration (Top 3 States):\")\n",
    "print(f\"Revenue share: {top3_revenue_share:.1f}%\")\n",
    "print(f\"Customer share: {top3_customer_share:.1f}%\")\n",
    "print(f\"Order share: {top3_order_share:.1f}%\")\n",
    "\n",
    "# Identify potential biases\n",
    "sp_dominance = state_summary.loc['SP', 'total_revenue'] / total_revenue * 100\n",
    "print(f\"\\nSP (São Paulo) alone represents {sp_dominance:.1f}% of total revenue\")\n",
    "print(f\"This indicates significant geographic concentration that could bias analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Key Insights and Trends Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend 1: Seasonal delivery performance\n",
    "delivered_orders['order_month'] = delivered_orders['order_purchase_timestamp'].dt.month\n",
    "delivered_orders['order_year'] = delivered_orders['order_purchase_timestamp'].dt.year\n",
    "\n",
    "monthly_performance = delivered_orders.groupby(['order_year', 'order_month']).agg({\n",
    "    'is_late': ['count', 'sum', 'mean'],\n",
    "    'delivery_delay_days': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "monthly_performance.columns = ['total_orders', 'late_orders', 'late_rate', 'avg_delay']\n",
    "monthly_performance = monthly_performance.reset_index()\n",
    "monthly_performance['year_month'] = monthly_performance['order_year'].astype(str) + '-' + monthly_performance['order_month'].astype(str).str.zfill(2)\n",
    "\n",
    "# Filter for complete months with significant volume\n",
    "monthly_performance = monthly_performance[monthly_performance['total_orders'] >= 1000]\n",
    "\n",
    "print(\"Trend 1: Monthly Delivery Performance\")\n",
    "print(\"Months with highest late delivery rates:\")\n",
    "print(monthly_performance.nlargest(5, 'late_rate')[['year_month', 'late_rate', 'avg_delay', 'total_orders']])\n",
    "\n",
    "# Trend 2: Price vs Delivery Performance correlation\n",
    "price_bins = pd.qcut(delivery_analysis['price'], 5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "price_performance = delivery_analysis.groupby(price_bins).agg({\n",
    "    'is_late': ['count', 'mean'],\n",
    "    'delivery_delay_days': 'mean',\n",
    "    'delivery_days': 'mean',\n",
    "    'price': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "price_performance.columns = ['total_orders', 'late_rate', 'avg_delay', 'avg_delivery_days', 'avg_price']\n",
    "\n",
    "print(\"\\nTrend 2: Price vs Delivery Performance\")\n",
    "print(price_performance)\n",
    "\n",
    "# Trend 3: Customer retention patterns\n",
    "customer_behavior = customer_orders.groupby('customer_unique_id').agg({\n",
    "    'order_purchase_timestamp': ['min', 'max', 'count'],\n",
    "    'payment_value': 'sum'\n",
    "})\n",
    "\n",
    "customer_behavior.columns = ['first_purchase', 'last_purchase', 'total_orders', 'total_spent']\n",
    "customer_behavior['customer_lifespan_days'] = (customer_behavior['last_purchase'] - customer_behavior['first_purchase']).dt.days\n",
    "\n",
    "retention_analysis = customer_behavior['total_orders'].value_counts().sort_index()\n",
    "retention_rate = {}\n",
    "for i in range(1, min(11, retention_analysis.index.max() + 1)):\n",
    "    retention_rate[i] = retention_analysis[retention_analysis.index >= i].sum() / len(customer_behavior) * 100\n",
    "\n",
    "print(\"\\nTrend 3: Customer Retention Analysis\")\n",
    "print(\"Percentage of customers making N+ orders:\")\n",
    "for orders, rate in retention_rate.items():\n",
    "    print(f\"{orders}+ orders: {rate:.1f}%\")\n",
    "\n",
    "one_time_customers = (customer_behavior['total_orders'] == 1).sum() / len(customer_behavior) * 100\n",
    "print(f\"\\nOne-time customers: {one_time_customers:.1f}%\")\n",
    "print(f\"Repeat customers: {100 - one_time_customers:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Strategic Recommendations Summary\n",
    "\n",
    "Based on the comprehensive analysis above, here are the key findings and strategic recommendations for the Head of Seller Relations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for recommendations\n",
    "print(\"=\" * 80)\n",
    "print(\"EXECUTIVE SUMMARY - KEY METRICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n📊 DELIVERY PERFORMANCE:\")\n",
    "print(f\"   • Overall late delivery rate: {delivered_orders['is_late'].mean()*100:.1f}%\")\n",
    "print(f\"   • Average delivery delay: {delivered_orders[delivered_orders['is_late']]['delivery_delay_days'].mean():.1f} days\")\n",
    "print(f\"   • Worst category: {category_performance.index[0]} ({category_performance.iloc[0]['late_rate']*100:.1f}% late rate)\")\n",
    "print(f\"   • Best category: {category_performance.index[-1]} ({category_performance.iloc[-1]['late_rate']*100:.1f}% late rate)\")\n",
    "\n",
    "print(f\"\\n👥 CUSTOMER SEGMENTS:\")\n",
    "champions_pct = (rfm_data['segment'] == 'Champions').mean() * 100\n",
    "at_risk_pct = (rfm_data['segment'] == 'At Risk').mean() * 100\n",
    "lost_pct = (rfm_data['segment'] == 'Lost Customers').mean() * 100\n",
    "print(f\"   • Champions: {champions_pct:.1f}% (Avg CLV: R$ {clv_by_segment.loc['Champions', 'avg_clv']:.2f})\")\n",
    "print(f\"   • At Risk: {at_risk_pct:.1f}% (Avg CLV: R$ {clv_by_segment.loc['At Risk', 'avg_clv']:.2f})\")\n",
    "print(f\"   • Lost Customers: {lost_pct:.1f}%\")\n",
    "\n",
    "print(f\"\\n🌍 GEOGRAPHIC CONCENTRATION:\")\n",
    "print(f\"   • Top 3 states control {top3_revenue_share:.1f}% of revenue\")\n",
    "print(f\"   • São Paulo alone: {sp_dominance:.1f}% of total revenue\")\n",
    "print(f\"   • One-time customers: {one_time_customers:.1f}%\")\n",
    "\n",
    "print(f\"\\n💰 FINANCIAL IMPACT:\")\n",
    "print(f\"   • Total estimated CLV: R$ {total_clv:,.0f}\")\n",
    "print(f\"   • Champions contribute: R$ {clv_by_segment.loc['Champions', 'total_clv']:,.0f}\")\n",
    "print(f\"   • At Risk customers: R$ {clv_by_segment.loc['At Risk', 'total_clv']:,.0f} at stake\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}